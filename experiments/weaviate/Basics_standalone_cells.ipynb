{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Weaviate operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses standalone cells which can be executed independently of each other. \n",
    "\n",
    "The code is designed to connect to a local Weaviate instance running with default port configuration. If you prefer to use the free cloud sandbox (which is deleted after 14 days), replace any instance of client with the code below. Make sure that the environment variables WCD_URL (REST url of the sandbox instance) and WCD_API_KEY are available in your environment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code to connect to a managed cloud weaviate instance is as follows:\n",
    "\n",
    "# client = weaviate.connect_to_weaviate_cloud(\n",
    "#     cluster_url=os.getenv(\"WCD_URL\"),\n",
    "#     auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WCD_API_KEY\")),\n",
    "#     headers={\n",
    "#         \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_APIKEY_RAGPOC\"]  # Replace with your inference API key\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data to the Weaviate instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY_RAGPOC\")\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Delete the collection in case it already exists to prevent a \"collection already exists\" error\n",
    "    client.collections.delete(\"Questions\")\n",
    "    \n",
    "    # ===== define collection =====\n",
    "    questions = client.collections.create(\n",
    "        name=\"Questions\",\n",
    "        vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),  # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also.\n",
    "        generative_config=wvc.config.Configure.Generative.openai()  # Ensure the `generative-openai` module is used for generative queries\n",
    "    )\n",
    "\n",
    "    # ===== import data =====\n",
    "    resp = requests.get('https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json')\n",
    "    data = json.loads(resp.text)  # Load data\n",
    "\n",
    "    question_objs = list()\n",
    "    for i, d in enumerate(data):\n",
    "        question_objs.append({\n",
    "            \"answer\": d[\"Answer\"],\n",
    "            \"question\": d[\"Question\"],\n",
    "            \"category\": d[\"Category\"],\n",
    "        })\n",
    "\n",
    "    questions = client.collections.get(\"Questions\")\n",
    "    questions.data.insert_many(question_objs)\n",
    "    \n",
    "finally:\n",
    "    client.close()  # Close client gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Weaviate instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the vectors for all objects in the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import os\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY_RAGPOC\")\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "    questions = client.collections.get(\"Questions\")\n",
    "    response = questions.query.fetch_objects(include_vector=True)\n",
    "    for o in response.objects:\n",
    "        print(o.vector)\n",
    "\n",
    "finally:\n",
    "    client.close()  # Close client gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import os\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY_RAGPOC\")\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "    questions = client.collections.get(\"Questions\")\n",
    "\n",
    "    response = questions.query.near_text(\n",
    "        query=\"biology\",\n",
    "        limit=2\n",
    "    )\n",
    "\n",
    "    print(response.objects[0].properties)  # Inspect the first object\n",
    "\n",
    "finally:\n",
    "    client.close()  # Close client gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search with a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import os\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY_RAGPOC\")\n",
    "    }\n",
    ")\n",
    "try:\n",
    "    questions = client.collections.get(\"Questions\")\n",
    "\n",
    "    response = questions.query.near_text(\n",
    "        query=\"biology\",\n",
    "        limit=2,\n",
    "        filters=wvc.query.Filter.by_property(\"category\").equal(\"ANIMALS\")\n",
    "    )\n",
    "\n",
    "    print(response.objects[0].properties)  # Inspect the first object\n",
    "\n",
    "finally:\n",
    "    client.close()  # Close client gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import os\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY_RAGPOC\")\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "    questions = client.collections.get(\"Questions\")\n",
    "\n",
    "    response = questions.generate.near_text(\n",
    "        query=\"biology\",\n",
    "        limit=2,\n",
    "        single_prompt=\"Write a limerick in only two lines about {answer}.\"\n",
    "    )\n",
    "\n",
    "    print(response.objects[0].generated)  # Inspect the first object\n",
    "\n",
    "finally:\n",
    "    client.close()  # Close client gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative search (grouped task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "import os\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_APIKEY_RAGPOC\")\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "    questions = client.collections.get(\"Questions\")\n",
    "\n",
    "    response = questions.generate.near_text(\n",
    "        query=\"biology\",\n",
    "        limit=2,\n",
    "        grouped_task=\"Write a tweet combining those topics\"\n",
    "    )\n",
    "\n",
    "    print(response.generated)  # Inspect the first object\n",
    "\n",
    "finally:\n",
    "    client.close()  # Close client gracefully"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
